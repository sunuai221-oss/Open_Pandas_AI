from __future__ import annotations

from time import perf_counter
from typing import Any, Dict, List, Optional

import pandas as pd

from agents.base import BaseAgent
from agents.registry import get_agent
from core import excel_utils
from core.error_handler import handle_code_error
from core.pipeline.atoms import (
    agent_policy_atom,
    domain_detector_atom,
    execute_atom,
    intent_detector_atom,
    llm_call_atom,
    llm_parse_atom,
    prompt_builder_atom,
    result_validation_atom,
    security_atom,
)
from core.pipeline.schemas import (
    AgentSelection,
    CodeExtraction,
    DatasetRef,
    DomainDetection,
    PipelineMetrics,
    PipelineResult,
    PromptBuildInput,
    SessionContext,
)


def run_pipeline(
    question: str,
    df: pd.DataFrame,
    session_context: SessionContext,
    agent_mode: str = "auto",
    selected_agent: Optional[BaseAgent] = None,
    detection: Optional[DomainDetection] = None,
    detected_skills: Optional[List[str]] = None,
    data_dictionary: Optional[Dict[str, Any]] = None,
    available_sheets: Optional[List[str]] = None,
    business_context: Optional[str] = None,
    dataset_name: Optional[str] = None,
    enable_correction: bool = True,
    max_correction_retries: int = 2,
) -> PipelineResult:
    total_start = perf_counter()

    dataset = DatasetRef.from_df(df, name=dataset_name)

    mode = (agent_mode or "auto").lower()
    domain_detection = detection
    if mode == "auto" and domain_detection is None:
        domain_detection = domain_detector_atom(df)

    if selected_agent is None:
        if mode == "auto":
            detected_domain = domain_detection.domain if domain_detection else "generic"
            selected_agent = get_agent(detected_domain)
        else:
            selected_agent = get_agent(mode)

    agent_selection = AgentSelection(
        mode=mode,
        active_domain=selected_agent.domain if selected_agent else "generic",
        active_agent_name=selected_agent.name if selected_agent else "Generic",
        detection=domain_detection,
    )

    intent_detection = intent_detector_atom(question)

    agent_context = {
        "language": session_context.language,
        "user_level": session_context.user_level,
        "df_columns": list(df.columns),
        "business_context": business_context,
    }

    agent_policy = agent_policy_atom(selected_agent, question, agent_context)
    domain_assets = agent_policy.domain_assets.model_dump() if agent_policy.domain_assets else None

    prompt_input = PromptBuildInput(
        df=df,
        question=question,
        context=session_context.memory_text or "",
        available_sheets=available_sheets,
        user_level=session_context.user_level,
        detected_skills=detected_skills,
        data_dictionary=data_dictionary,
        business_context=business_context,
        agent_prompt=agent_policy.agent_prompt,
        agent_plan=agent_policy.agent_plan,
        domain_assets=domain_assets,
    )

    prompt_output = prompt_builder_atom(prompt_input)

    llm_raw = llm_call_atom(prompt_output.prompt, session_context.provider, session_context.model)
    llm_parse = llm_parse_atom(llm_raw)

    if not llm_parse.code.strip():
        metrics = PipelineMetrics(
            llm_latency_ms=llm_raw.latency_ms,
            total_ms=(perf_counter() - total_start) * 1000.0,
        )
        return PipelineResult(
            status="error",
            error_stage="llm_parse",
            error_message="Empty code generated by the LLM.",
            question=question,
            dataset=dataset,
            session_context=session_context,
            agent_selection=agent_selection,
            intent_detection=intent_detection,
            agent_policy=agent_policy,
            prompt=prompt_output,
            llm_raw=llm_raw,
            llm_parse=llm_parse,
            security=None,
            execution=None,
            validation=None,
            metrics=metrics,
        )

    security = security_atom(llm_parse.code)
    if not security.is_safe:
        metrics = PipelineMetrics(
            llm_latency_ms=llm_raw.latency_ms,
            total_ms=(perf_counter() - total_start) * 1000.0,
        )
        return PipelineResult(
            status="blocked",
            error_stage="security",
            error_message=security.reason or "Unsafe code blocked.",
            question=question,
            dataset=dataset,
            session_context=session_context,
            agent_selection=agent_selection,
            intent_detection=intent_detection,
            agent_policy=agent_policy,
            prompt=prompt_output,
            llm_raw=llm_raw,
            llm_parse=llm_parse,
            security=security,
            execution=None,
            validation=None,
            metrics=metrics,
        )

    exec_start = perf_counter()
    execution = execute_atom(llm_parse.code, df)
    execution_ms = (perf_counter() - exec_start) * 1000.0

    correction_attempts = 0
    correction_applied = False
    if enable_correction and execution.status == "error" and execution.error_message:
        for new_code in handle_code_error(
            prompt_output.prompt,
            llm_parse.code,
            execution.error_message,
            max_retries=max_correction_retries,
            llm_provider=session_context.provider,
            llm_model=session_context.model,
        ):
            correction_attempts += 1
            candidate_security = security_atom(new_code)
            if not candidate_security.is_safe:
                continue
            exec_start = perf_counter()
            candidate_execution = execute_atom(new_code, df)
            execution_ms = (perf_counter() - exec_start) * 1000.0
            if candidate_execution.status == "success":
                correction_applied = True
                llm_parse = CodeExtraction(
                    code=new_code,
                    method="correction",
                    warnings=["Code corrected after execution error."],
                )
                security = candidate_security
                execution = candidate_execution
                break

    if execution.result is not None:
        execution.can_export_excel = excel_utils.should_export_to_excel(
            question=question,
            code=llm_parse.code,
            result=execution.result,
        )
        execution.can_generate_chart = isinstance(execution.result, pd.DataFrame) and not execution.result.empty

    validation = None
    if execution.result is not None:
        validation = result_validation_atom(
            result=execution.result,
            question=question,
            df=df,
            detected_skills=detected_skills,
        )

    status = "success" if execution.status == "success" else "error"
    error_stage = "execution" if execution.status == "error" else None
    error_message = execution.error_message if execution.status == "error" else None

    metrics = PipelineMetrics(
        llm_latency_ms=llm_raw.latency_ms,
        execution_ms=execution_ms,
        total_ms=(perf_counter() - total_start) * 1000.0,
        correction_attempts=correction_attempts,
        correction_applied=correction_applied,
    )

    return PipelineResult(
        status=status,
        error_stage=error_stage,
        error_message=error_message,
        question=question,
        dataset=dataset,
        session_context=session_context,
        agent_selection=agent_selection,
        intent_detection=intent_detection,
        agent_policy=agent_policy,
        prompt=prompt_output,
        llm_raw=llm_raw,
        llm_parse=llm_parse,
        security=security,
        execution=execution,
        validation=validation,
        metrics=metrics,
    )
