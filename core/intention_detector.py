"""
D√©tecteur d'intentions pour les questions analytiques.
Identifie 15+ intentions sp√©cifiques pour g√©n√©rer un code optimis√©.
"""

from typing import Dict, List, Set
import re


class IntentionDetector:
    """D√©tecte les intentions analytiques dans une question utilisateur."""
    
    # Mots-cl√©s pour chaque intention
    FILTERING_KEYWORDS = {
        'filter', 'where', 'o√π', 'avec', 'sans', 'sauf', 'uniquement', 'seul',
        'exclude', 'exclure', 'supprimer', 'remove', 'greater', 'less', 'plus', 'moins',
        'entre', 'between', 'depuis', 'until', 'pendant', 'au-del√†', 'only', 'just'
    }
    
    SORTING_KEYWORDS = {
        'sort', 'trier', 'order', 'ordonner', 'classement', 'ranking',
        'top', 'meilleur', 'best', 'worst', 'pire', 'croissant', 'd√©croissant',
        'ascending', 'descending', 'asc', 'desc', 'ranked', 'hi√©rarchie'
    }
    
    STATISTICAL_KEYWORDS = {
        'moyenne', 'average', 'mean', 'median', 'm√©diane', 'mode', 'std', '√©cart-type',
        'variance', 'percentile', 'quartile', 'quantile', 'distribution', 'summary',
        'r√©sum√©', 'statistique', 'stat', 'correlation', 'corr√©lation'
    }
    
    AGGREGATION_KEYWORDS = {
        'total', 'sum', 'somme', 'count', 'nombre', 'nombre de', 'combien',
        'aggregate', 'agr√©gation', 'regrouper', 'group', 'groupby', 'par groupe',
        'accumulate', 'cumulative', 'cumul√©', 'cumul√©e'
    }
    
    TIME_SERIES_KEYWORDS = {
        'date', 'temps', 'time', 's√©rie', 'series', 'temporelle', 'trend', 'tendance',
        'jour', 'day', 'mois', 'month', 'ann√©e', 'year', 'p√©riode', 'period',
        'historique', 'history', 'chronologique', 'evolution', '√©volution'
    }
    
    JOIN_KEYWORDS = {
        'fusionner', 'merge', 'joindre', 'join', 'combiner', 'combine',
        'concatenate', 'concat√©ner', 'liaison', 'relation', 'lier'
    }
    
    ANOMALY_KEYWORDS = {
        'anomalie', 'anomaly', 'outlier', 'aberrant', 'bizarre', 'strange',
        'inusuel', 'unusual', 'erreur', 'error', 'suspect', 'suspicious',
        'valeur aberrante', 'extr√™me', 'extreme'
    }
    
    TRANSFORMATION_KEYWORDS = {
        'transformer', 'transform', 'convertir', 'convert', 'calculer', 'calculate',
        'd√©river', 'derive', 'cr√©er', 'create', 'g√©n√©rer', 'generate',
        'normaliser', 'normalize', 'standardiser', 'standardize', 'formater', 'format'
    }
    
    DUPLICATE_KEYWORDS = {
        'doublon', 'duplicate', 'dupliqu√©', 'unique', 'distinct', 'deduplicate',
        'suppression de doublons', 'remove duplicates', 'occurrences'
    }
    
    MISSING_KEYWORDS = {
        'vide', 'empty', 'manquant', 'missing', 'null', 'nan', 'absent',
        'compl√©tude', 'completeness', 'remplir', 'fill', 'imputer'
    }
    
    SEGMENT_KEYWORDS = {
        'segmenter', 'segment', 'cat√©gorie', 'category', 'groupe', 'group',
        'classification', 'classify', 'profil', 'profile', 'type', 'classe'
    }
    
    RANKING_KEYWORDS = {
        'rang', 'rank', 'position', 'classement', 'scoring', 'score',
        'percentile', 'percentil', 'top n', 'bottom'
    }
    
    COMPARISON_KEYWORDS = {
        'comparer', 'compare', 'diff√©rence', 'difference', 'vs', 'versus',
        '√©cart', 'gap', 'changement', 'change', '√©volution', 'variation'
    }
    
    PIVOT_KEYWORDS = {
        'pivot', 'tableau crois√©', 'crosstab', 'cross-tab', 'r√©sum√© par',
        'agr√©gation par', 'dimension', 'mesure'
    }
    
    PATTERN_KEYWORDS = {
        'pattern', 'motif', 'tendance', 'trend', 'r√©gularit√©', 'r√®gle',
        'r√©currence', 'recurrence', 'cyclique', 'cyclical'
    }
    
    EXPORT_KEYWORDS = {
        'export', 'exporter', 't√©l√©charger', 'download', 'sauvegarder',
        'save', 'enregistrer', 'excel', 'csv', 'json'
    }
    
    @classmethod
    def detect_all(cls, question: str) -> Dict[str, bool]:
        """
        D√©tecte toutes les intentions dans une question.
        
        Args:
            question: Question de l'utilisateur
        
        Returns:
            Dict avec toutes les intentions d√©tect√©es
        """
        question_lower = question.lower()
        
        return {
            'filtering': cls._has_keywords(question_lower, cls.FILTERING_KEYWORDS),
            'sorting': cls._has_keywords(question_lower, cls.SORTING_KEYWORDS),
            'statistical': cls._has_keywords(question_lower, cls.STATISTICAL_KEYWORDS),
            'aggregation': cls._has_keywords(question_lower, cls.AGGREGATION_KEYWORDS),
            'time_series': cls._has_keywords(question_lower, cls.TIME_SERIES_KEYWORDS),
            'join': cls._has_keywords(question_lower, cls.JOIN_KEYWORDS),
            'anomaly_detection': cls._has_keywords(question_lower, cls.ANOMALY_KEYWORDS),
            'transformation': cls._has_keywords(question_lower, cls.TRANSFORMATION_KEYWORDS),
            'duplicate_handling': cls._has_keywords(question_lower, cls.DUPLICATE_KEYWORDS),
            'missing_values': cls._has_keywords(question_lower, cls.MISSING_KEYWORDS),
            'segmentation': cls._has_keywords(question_lower, cls.SEGMENT_KEYWORDS),
            'ranking': cls._has_keywords(question_lower, cls.RANKING_KEYWORDS),
            'comparison': cls._has_keywords(question_lower, cls.COMPARISON_KEYWORDS),
            'pivot_table': cls._has_keywords(question_lower, cls.PIVOT_KEYWORDS),
            'pattern_detection': cls._has_keywords(question_lower, cls.PATTERN_KEYWORDS),
            'export': cls._has_keywords(question_lower, cls.EXPORT_KEYWORDS),
        }
    
    @classmethod
    def detect_primary(cls, question: str) -> List[str]:
        """
        D√©tecte les intentions primaires (les plus importantes).
        
        Args:
            question: Question de l'utilisateur
        
        Returns:
            Liste des intentions primaires par ordre d'importance
        """
        all_intentions = cls.detect_all(question)
        primary = [k for k, v in all_intentions.items() if v]
        
        # Tri par priorit√© heuristique
        priority_order = [
            'pivot_table', 'aggregation', 'filtering', 'sorting',
            'statistical', 'transformation', 'time_series',
            'comparison', 'segmentation', 'ranking'
        ]
        
        primary_sorted = sorted(
            primary,
            key=lambda x: priority_order.index(x) if x in priority_order else 999
        )
        
        return primary_sorted[:3]  # Top 3 intentions
    
    @classmethod
    def get_instructions(cls, intentions: Dict[str, bool]) -> str:
        """
        G√©n√®re les instructions sp√©cifiques bas√©es sur les intentions d√©tect√©es.
        
        Args:
            intentions: Dict des intentions
        
        Returns:
            String avec instructions pour le prompt
        """
        instructions = []
        
        if intentions.get('pivot_table'):
            instructions.append(
                "üìä PIVOT TABLE D√âTECT√âE:\n"
                "- Utilise df.pivot_table(values='...', index='...', columns='...', aggfunc='...')\n"
                "- Fonctions d'agr√©gation: 'sum', 'mean', 'count', 'min', 'max', 'std'\n"
                "- Termine par .reset_index() pour un DataFrame propre"
            )
        
        if intentions.get('aggregation'):
            instructions.append(
                "üìà AGR√âGATION D√âTECT√âE:\n"
                "- Utilise df.groupby(...).agg({...}) pour regrouper\n"
                "- Sp√©cifie clairement les colonnes √† grouper et √† agr√©ger\n"
                "- N'oublie pas .reset_index() si le r√©sultat doit √™tre un DataFrame"
            )
        
        if intentions.get('filtering'):
            instructions.append(
                "üîç FILTRAGE D√âTECT√â:\n"
                "- Utilise des conditions bool√©ennes: df[df['col'] > valeur]\n"
                "- Combine avec & (et) ou | (ou), pas 'and'/'or'\n"
                "- V√©rifie que les valeurs et types de colonnes sont corrects"
            )
        
        if intentions.get('sorting'):
            instructions.append(
                "üî§ TRI D√âTECT√â:\n"
                "- Utilise df.sort_values(by=['col1', 'col2'], ascending=[True, False])\n"
                "- Pr√©cise si croissant (ascending=True) ou d√©croissant (ascending=False)\n"
                "- N'oublie pas .reset_index(drop=True) pour les index continus"
            )
        
        if intentions.get('statistical'):
            instructions.append(
                "üìä STATISTIQUES D√âTECT√âES:\n"
                "- Pour moyenne: df['col'].mean()\n"
                "- Pour √©cart-type: df['col'].std()\n"
                "- Pour percentile: df['col'].quantile(0.25 / 0.50 / 0.75)\n"
                "- Utilise describe() pour un r√©sum√© complet"
            )
        
        if intentions.get('time_series'):
            instructions.append(
                "‚è∞ S√âRIE TEMPORELLE D√âTECT√âE:\n"
                "- Assure-toi que la colonne date est en format datetime\n"
                "- Utilise df['date'].dt.year / .month / .day pour extraire\n"
                "- Pour grouper par p√©riode: df.groupby(df['date'].dt.to_period('M'))"
            )
        
        if intentions.get('transformation'):
            instructions.append(
                "üîÑ TRANSFORMATION D√âTECT√âE:\n"
                "- Pour nouvelles colonnes: df['new_col'] = df['col1'] + df['col2']\n"
                "- Pour conversions: df['col'].astype(type)\n"
                "- Pour nettoyage texte: df['col'].str.lower() / .str.strip()"
            )
        
        if intentions.get('anomaly_detection'):
            instructions.append(
                "‚ö†Ô∏è D√âTECTION D'ANOMALIES:\n"
                "- Utilise l'√©cart-type: mean ¬± 3*std pour les outliers\n"
                "- IQR method: Q1 - 1.5*IQR ou Q3 + 1.5*IQR\n"
                "- Identifie les valeurs NULL et les doublons"
            )
        
        if intentions.get('comparison'):
            instructions.append(
                "‚öñÔ∏è COMPARAISON D√âTECT√âE:\n"
                "- Utilise des groupby avec diff() ou pct_change() pour les variations\n"
                "- Compare les distributions avec describe() sur les groupes\n"
                "- Calcule l'√©cart absolu ou en pourcentage"
            )
        
        if intentions.get('segmentation'):
            instructions.append(
                "üéØ SEGMENTATION D√âTECT√âE:\n"
                "- Utilise pd.cut() pour cr√©er des tranches num√©riques\n"
                "- Utilise pd.qcut() pour d√©couper par quantiles\n"
                "- Utilise groupby() pour analyser par segment"
            )
        
        if intentions.get('ranking'):
            instructions.append(
                "üèÜ RANKING D√âTECT√â:\n"
                "- Utilise df.nlargest(n, 'col') ou df.nsmallest(n, 'col')\n"
                "- Pour un rang: df['rank'] = df['col'].rank(method='dense')\n"
                "- Trie ensuite par rang d√©croissant"
            )
        
        if intentions.get('duplicate_handling'):
            instructions.append(
                "üîÅ DOUBLONS D√âTECT√âS:\n"
                "- Pour les identifier: df[df.duplicated()]\n"
                "- Pour les supprimer: df.drop_duplicates()\n"
                "- Par colonne sp√©cifique: df.drop_duplicates(subset=['col'])"
            )
        
        if intentions.get('missing_values'):
            instructions.append(
                "‚äò VALEURS MANQUANTES D√âTECT√âES:\n"
                "- Pour les identifier: df.isnull().sum()\n"
                "- Pour les remplir: df.fillna(value)\n"
                "- Pour les supprimer: df.dropna()"
            )
        
        if intentions.get('join'):
            instructions.append(
                "üîó FUSION D√âTECT√âE:\n"
                "- Cette application ne g√®re qu'un DataFrame √† la fois\n"
                "- Explique comment fusionner manuellement les donn√©es\n"
                "- Ou cr√©e une variable 'result' avec les √©tapes"
            )
        
        if intentions.get('pattern_detection'):
            instructions.append(
                "üîé MOTIF/TENDANCE D√âTECT√â:\n"
                "- Utilise groupby pour identifier les motifs\n"
                "- V√©rifie la corr√©lation avec .corr()\n"
                "- Cherche les cycles ou r√©currences"
            )
        
        if instructions:
            return "\n\nüéØ INSTRUCTIONS SP√âCIALIS√âES:\n" + "\n\n".join(instructions) + "\n"
        
        return ""
    
    @staticmethod
    def _has_keywords(text: str, keywords: Set[str]) -> bool:
        """
        V√©rifie si au moins un mot-cl√© est pr√©sent dans le texte.
        
        Args:
            text: Texte √† analyser
            keywords: Ensemble de mots-cl√©s
        
        Returns:
            True si au moins un mot-cl√© trouv√©
        """
        # Tokenize basique
        words = re.findall(r'\b\w+\b', text)
        return any(word in keywords for word in words)
