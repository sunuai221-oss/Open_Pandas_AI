"""
Page Agent - Interface de conversation IA principale.
"""

import streamlit as st
import pandas as pd
from datetime import datetime

# Configuration
st.set_page_config(
    page_title="Open Pandas-AI - Agent IA",
    page_icon="ü§ñ",
    layout="wide"
)

from components.sidebar import render_sidebar
from components.memory_viewer import render_memory_context_banner, render_memory_panel
from components.suggestions import render_followup_suggestions
from components.chat_interface import render_chat_message, render_chat_input, render_chat_history
from components.result_display import render_result
from components.skills_catalog import detect_skill_from_question
from core.session_manager import get_session_manager
from core.memory import SessionMemory
from core.prompt_builder import build_prompt
from core.llm import call_llm
from core.intention_detector import IntentionDetector
from core.formatter import format_result, format_result_with_validation
import requests
from core.executor import execute_code
from core.code_security import is_code_safe
from core.error_handler import handle_code_error
from core.consulting import auto_comment_agent
from core.visualization import generate_and_run_visualization
from core.business_examples import get_business_example
from core import excel_utils
from db.session import get_session as get_db_session
from db.models import Question, CodeExecution, ConsultingMessage

# Session
session = get_session_manager()
memory = SessionMemory()

llm_provider = session.llm_provider
llm_model = session.llm_model
provider_labels = {
    "codestral": "Codestral",
    "ollama": "Ollama",
    "lmstudio": "LM Studio",
}
provider_label = provider_labels.get((llm_provider or "").lower(), llm_provider or "Unknown")
model_used_label = f"{provider_label} ({llm_model})" if llm_model else provider_label
business_context = None
if session.business_example_key:
    example = get_business_example(session.business_example_key)
    if example:
        business_context = f"{example.get('dataset_name', session.business_example_key)} ({example.get('domain', 'unknown')})"
    else:
        business_context = session.business_example_key
elif session.business_domain and session.business_domain != "auto":
    business_context = session.business_domain

# Sidebar
render_sidebar()

# Header
st.title("ü§ñ Agent IA")

if not session.has_data:
    st.warning("‚ö†Ô∏è Aucune donn√©e charg√©e")
    st.info("Chargez un fichier pour commencer √† poser des questions.")
    if st.button("üè† Charger des donn√©es"):
        st.switch_page("pages/1_üè†_Home.py")
    st.stop()

df = session.df
analysis_df = session.df_norm if session.df_norm is not None else df

# Data info bar
col1, col2, col3 = st.columns([2, 1, 1])
with col1:
    st.markdown(f"**üìä {session.df_name}** ‚Äî {len(df):,} lignes √ó {len(df.columns)} colonnes")
with col2:
    if session.quality_score:
        if session.quality_score >= 80:
            st.success(f"‚úì Qualit√©: {session.quality_score:.0f}")
        else:
            st.warning(f"‚ö†Ô∏è Qualit√©: {session.quality_score:.0f}")
with col3:
    if st.button("üìä Explorer", key="agent_explore"):
        st.switch_page("pages/2_üìä_Data_Explorer.py")

st.markdown("---")

# Memory context banner
render_memory_context_banner()

# Dataset preview (only before first exchange)
if session.has_data and not session.exchanges:
    st.markdown("### üìä Aper√ßu des donn√©es")
    col_a, col_b = st.columns(2)
    with col_a:
        st.metric("Lignes", f"{len(df):,}")
    with col_b:
        st.metric("Colonnes", f"{len(df.columns):,}")

    preview_rows = 10
    st.dataframe(df.head(preview_rows), use_container_width=True)
    st.caption(f"Affichage: {min(preview_rows, len(df))} premi√®res lignes")
    st.markdown("---")

# Chat input
st.markdown("### üí¨ Posez votre question")

# Check for suggested question
question = None
if 'suggested_question' in st.session_state and st.session_state['suggested_question']:
    question = st.session_state['suggested_question']
    st.session_state['suggested_question'] = None
    st.info(f"üí° Question sugg√©r√©e: {question}")

# Input form
with st.form(key="agent_question_form", clear_on_submit=False):
    user_question = st.text_input(
        "Question",
        value=question or "",
        placeholder="Ex: Quels sont les 5 meilleurs produits par ventes ?",
        key="agent_question_input",
        label_visibility="collapsed"
    )
    
    col1, col2, col3 = st.columns([3, 1, 1])
    with col1:
        submit = st.form_submit_button("üöÄ Analyser", use_container_width=True, type="primary")
    with col2:
        generate_viz = st.form_submit_button("üìà + Graphique", use_container_width=True)
    with col3:
        export_result = st.form_submit_button("üì• + Export", use_container_width=True)

# Process question
if (submit or generate_viz or export_result) and user_question:
    question = user_question.strip()
    
    # V√©rifier que la question n'est pas vide
    if not question:
        st.warning("‚ö†Ô∏è Veuillez saisir une question.")
        st.stop()
    
    # Wrapper global pour garantir l'affichage m√™me en cas d'erreur
    st.write("üîç **Debug:** D√©but du traitement de la question")
    
    exchange = {
        "question": question,
        "timestamp": datetime.now().strftime("%H:%M"),
        "prompt": "",
        "code": "",
        "result": None,
        "auto_comment": "",
        "vis_img": None,
    }
    
    # Flag pour savoir si on doit continuer
    should_continue = True
    
    try:
        # Afficher un indicateur de traitement
        st.info(f"üí¨ Traitement de la question: {question[:50]}...")
        st.write("üîç **Debug:** Entr√©e dans le bloc try principal")
        
        # Detect skills
        detected_skills = detect_skill_from_question(question)
        if detected_skills:
            skills_names = [s['name'] for s in detected_skills]
            st.caption(f"üõ†Ô∏è Comp√©tences d√©tect√©es: {', '.join(skills_names)}")
        
        # Detect intentions (Phase 1)
        intentions = IntentionDetector.detect_all(question)
        primary_intentions = IntentionDetector.detect_primary(question)
        if primary_intentions:
            st.caption(f"üéØ Intentions d√©tect√©es: {', '.join(primary_intentions[:3])}")
        
        # Add to memory
        memory.append("user", question, timestamp=datetime.now().isoformat())
        
        # Process with LLM
        code = None
        try:
            # V√©rifier que l'API key est configur√©e
            import os
            api_key = os.getenv("MISTRAL_API_KEY")
            if not api_key or api_key == "VOTRE_CLE_CODESRAL_ICI":
                st.error("‚ùå **Erreur de configuration** : La cl√© API Mistral n'est pas configur√©e.")
                st.info("üí° Veuillez d√©finir la variable d'environnement `MISTRAL_API_KEY` dans un fichier `.env` √† la racine du projet.")
                st.code("MISTRAL_API_KEY=votre_cle_api_ici", language="bash")
                st.stop()
            
            with st.spinner("üß† G√©n√©ration du code..."):
                # Build prompt with enhanced context (Phase 1)
                context = memory.as_string(last_n=3)
                available_sheets = list(session.all_sheets.keys()) if session.all_sheets else None
                
                # Get skills list for prompt
                skills_list = None
                if detected_skills:
                    skills_list = [s['name'] for s in detected_skills]
                
                # Get data dictionary from session if available
                data_dictionary = st.session_state.get('data_dictionary')
                
                # Build enriched prompt with intentions
                prompt = build_prompt(
                    df=analysis_df,
                    question=question,
                    context=context,
                    available_sheets=available_sheets,
                    user_level=session.user_level,
                    detected_skills=skills_list,
                    data_dictionary=data_dictionary,
                    business_context=business_context
                )
                exchange["prompt"] = prompt
                
                # Call LLM
                st.write(f"üì° Appel de l'API {provider_label}...")
                code = call_llm(prompt, model=llm_model, provider=llm_provider)
                st.write(f"‚úÖ Code re√ßu ({len(code)} caract√®res)")
                
                # V√©rifier que le code n'est pas vide
                if not code or len(code.strip()) == 0:
                    st.error("‚ùå L'IA n'a pas g√©n√©r√© de code. Veuillez r√©essayer.")
                    should_continue = False
                    exchange["result"] = "Erreur: Code vide g√©n√©r√© par l'IA"
                    exchange["auto_comment"] = "L'IA n'a pas g√©n√©r√© de code valide."
                else:
                    exchange["code"] = code
                    
                    # Security check
                    is_safe, reason = is_code_safe(code)
                    if not is_safe:
                        st.error(f"‚ö†Ô∏è Code non s√©curis√©: {reason}")
                        with st.expander("üîß Code g√©n√©r√© (non s√©curis√©)"):
                            st.code(code, language="python")
                        should_continue = False
                        exchange["result"] = f"Erreur: Code non s√©curis√© - {reason}"
                        exchange["auto_comment"] = "Le code g√©n√©r√© a √©t√© bloqu√© pour des raisons de s√©curit√©."
        except requests.exceptions.RequestException as e:
            st.error(f"‚ùå **Erreur de connexion API** : {str(e)}")
            st.info("üí° V√©rifiez votre connexion internet et que votre cl√© API Mistral est valide.")
            st.exception(e)
            should_continue = False
            exchange["result"] = f"Erreur API: {str(e)}"
            exchange["auto_comment"] = "Impossible de contacter l'API Mistral."
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la g√©n√©ration du code: {str(e)}")
            st.exception(e)
            should_continue = False
            exchange["result"] = f"Erreur: {str(e)}"
            exchange["auto_comment"] = "Une erreur s'est produite lors de la g√©n√©ration du code."
        
        # Si on ne peut pas continuer, afficher quand m√™me ce qu'on a
        if not should_continue:
            session.add_exchange(exchange)
            st.markdown("---")
            st.markdown("### ü§ñ R√©ponse")
            st.error(exchange.get("result", "Erreur inconnue"))
            if exchange.get("auto_comment"):
                st.info(f"üß† **Analyse:** {exchange['auto_comment']}")
            st.stop()
        
        # Execute code
        raw_result = None
        formatted = None
        validation = None
        try:
            with st.spinner("‚ö° Ex√©cution..."):
                raw_result = execute_code(code, analysis_df)
                
                # Error handling with auto-correction
                if isinstance(raw_result, str) and raw_result.startswith("Erreur"):
                    st.warning("‚ö†Ô∏è Erreur d√©tect√©e, tentative de correction...")
                    
                    correction_attempted = False
                    for new_code in handle_code_error(prompt, code, str(raw_result), max_retries=2, llm_provider=llm_provider, llm_model=llm_model):
                        is_safe, reason = is_code_safe(new_code)
                        if not is_safe:
                            continue
                        
                        correction_attempted = True
                        candidate = execute_code(new_code, df)
                        if not (isinstance(candidate, str) and candidate.startswith("Erreur")):
                            st.success("‚úÖ Correction r√©ussie!")
                            raw_result = candidate
                            code = new_code
                            exchange["code"] = new_code
                            break
                    
                    # Si la correction a √©chou√©, afficher l'erreur
                    if isinstance(raw_result, str) and raw_result.startswith("Erreur"):
                        st.error(f"‚ùå Erreur d'ex√©cution: {raw_result}")
                        with st.expander("üîß Code g√©n√©r√© (avec erreur)"):
                            st.code(code, language="python")
                
                if raw_result is not None:
                    # Validation et enrichissement du r√©sultat (Phase 1)
                    validation = format_result_with_validation(
                        result=raw_result,
                        question=question,
                        original_df=analysis_df,
                        detected_skills=[s['name'] for s in detected_skills] if detected_skills else None
                    )
                    formatted = validation['formatted']
                    exchange["result"] = formatted
                    exchange["validation"] = validation
                else:
                    st.error("‚ùå Aucun r√©sultat retourn√© par l'ex√©cution du code.")
                    formatted = "Erreur: Aucun r√©sultat"
                    exchange["result"] = formatted
        except Exception as e:
            st.error(f"‚ùå Erreur lors de l'ex√©cution du code: {str(e)}")
            st.exception(e)
            formatted = f"Erreur: {str(e)}"
            exchange["result"] = formatted
            raw_result = formatted
        
        # Consulting analysis (disabled as per user request)
        auto_comment = "" # R√©sultat g√©n√©r√© avec succ√®s.  # Valeur par d√©faut
        # if raw_result is not None:
        #     try:
        #         with st.spinner("üß† Analyse professionnelle..."):
        #             auto_comment = auto_comment_agent(df=df, result=raw_result, lang=session.language, llm_model=llm_model, llm_provider=llm_provider)
        #             if not auto_comment or len(auto_comment.strip()) == 0:
        #                 auto_comment = "Analyse g√©n√©r√©e avec succ√®s."
        #             exchange["auto_comment"] = auto_comment
        #             memory.append("assistant", auto_comment[:200], timestamp=datetime.now().isoformat())
        #     except Exception as e:
        #         st.warning(f"‚ö†Ô∏è Erreur lors de l'analyse professionnelle: {str(e)}")
        #         auto_comment = "R√©sultat g√©n√©r√© avec succ√®s."
        #         exchange["auto_comment"] = auto_comment
        # else:
        #     auto_comment = "Erreur lors de l'ex√©cution."
        #     exchange["auto_comment"] = auto_comment
        
        # Save to database (optionnel - ne bloque pas l'affichage)
        try:
            user_id = st.session_state.get('user_id')
            if user_id is None:
                # Essayer de r√©cup√©rer ou cr√©er l'utilisateur
                from db.queries import get_or_create_user
                with get_db_session() as db_session:
                    user = get_or_create_user(db_session, session.session_id)
                    user_id = user.id
                    st.session_state['user_id'] = user_id
            
            with get_db_session() as db_session:
                q = Question(question=question, user_id=user_id, file_id=st.session_state.get('file_id'))
                db_session.add(q)
                db_session.commit()
                db_session.refresh(q)
                
                is_error = raw_result is None or (
                    isinstance(raw_result, str) and raw_result.startswith('Erreur')
                )
                result_text = "" if formatted is None else str(formatted)[:1000]
                ce = CodeExecution(
                    code=code,
                    result=result_text,
                    status='error' if is_error else 'success',
                    error_message=str(raw_result)[:500] if isinstance(raw_result, str) and raw_result.startswith('Erreur') else None,
                    model_used=model_used_label,
                    question_id=q.id
                )
                db_session.add(ce)
                
                cm = ConsultingMessage(
                    message=auto_comment,
                    role="assistant",
                    model_used=model_used_label,
                    question_id=q.id
                )
                db_session.add(cm)
                db_session.commit()
        except Exception as e:
            # Ne pas bloquer l'affichage si la DB √©choue
            st.warning(f"‚ö†Ô∏è Erreur lors de la sauvegarde en base de donn√©es (non bloquant): {str(e)[:100]}")
        
        # Visualization if requested
        if generate_viz and isinstance(formatted, pd.DataFrame) and not formatted.empty:
            with st.spinner("üìà G√©n√©ration du graphique..."):
                vis_img, vis_info = generate_and_run_visualization(formatted, question, llm_provider=llm_provider, llm_model=llm_model)
                if vis_img:
                    exchange["vis_img"] = vis_img
                    exchange["vis_info"] = vis_info
        
        # Add exchange to session (doit √™tre fait avant l'affichage)
        session.add_exchange(exchange)
        
        st.markdown("---")
        
        # Display result with enhanced information (Phase 1)
        st.markdown("### ü§ñ R√©ponse")
        
        # Afficher les warnings si pr√©sents
        if validation and validation.get('warnings'):
            for warning in validation['warnings']:
                st.warning(warning)
        
        # Afficher l'interpr√©tation si pr√©sente
        if validation and validation.get('interpretation'):
            st.info(f"üí° {validation['interpretation']}")
        
        # Result
        if isinstance(formatted, pd.DataFrame):
            if not formatted.empty:
                max_rows = session.display_max_rows
                display_df = formatted if max_rows == "Toutes" else formatted.head(int(max_rows))
                st.dataframe(display_df, use_container_width=True)
                st.caption(f"Affichage: {len(display_df)} / {len(formatted)} lignes")
                
                # Contexte statistique si disponible
                if validation and validation.get('context'):
                    ctx = validation['context']
                    col_a, col_b, col_c = st.columns(3)
                    with col_a:
                        if 'shape' in ctx:
                            st.metric("Dimensions", ctx['shape'])
                    with col_b:
                        if 'full_rows' in ctx:
                            st.metric("Total complet", f"{ctx['full_rows']:,} lignes")
                    with col_c:
                        if 'quality_score' in validation:
                            score = validation['quality_score']
                            st.metric("Qualit√© r√©sultat", f"{score}%")
                
                # Actions
                col1, col2, col3 = st.columns(3)
                with col1:
                    try:
                        buffer = excel_utils.export_dataframe_to_buffer(formatted)
                        st.download_button(
                            "üì• T√©l√©charger Excel",
                            data=buffer,
                            file_name=f"resultat_{datetime.now().strftime('%H%M%S')}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key=f"result_excel_{len(session.exchanges)}"
                        )
                    except Exception as e:
                        st.error(f"Erreur export: {e}")
                with col2:
                    if st.button("üìà G√©n√©rer graphique", key=f"result_viz_{len(session.exchanges)}"):
                        try:
                            with st.spinner("G√©n√©ration..."):
                                vis_img, _ = generate_and_run_visualization(formatted, question, llm_provider=llm_provider, llm_model=llm_model)
                                if vis_img:
                                    st.image(vis_img)
                        except Exception as e:
                            st.error(f"Erreur visualisation: {e}")
                with col3:
                    pass
                
                # Suggestions de suivi
                if validation and validation.get('suggestions'):
                    with st.expander("üí¨ Questions de suivi sugg√©r√©es"):
                        for i, suggestion in enumerate(validation['suggestions'], 1):
                            st.write(f"{i}. {suggestion}")
            else:
                st.warning("‚ö†Ô∏è Le r√©sultat est un DataFrame vide.")
        elif formatted is not None:
            st.write(formatted)
        else:
            st.error("‚ùå Aucun r√©sultat √† afficher.")
        
        # Visualization
        if exchange.get("vis_img"):
            st.image(exchange["vis_img"], caption="üìà Visualisation g√©n√©r√©e")
        
        # Code (if expert mode)
        if session.show_code and code:
            with st.expander("üîß Code g√©n√©r√©"):
                st.code(code, language="python")
        
        # Followup suggestions
        if formatted is not None and not (isinstance(formatted, pd.DataFrame) and formatted.empty):
            render_followup_suggestions(question, formatted)
        
        # Message de confirmation
        st.success("‚úÖ Traitement termin√© avec succ√®s!")
    
    except Exception as global_error:
        # En cas d'erreur globale, afficher au moins un message
        st.error(f"‚ùå Erreur critique lors du traitement: {str(global_error)}")
        st.exception(global_error)
        
        # Essayer d'afficher ce qui a pu √™tre g√©n√©r√©
        if 'exchange' in locals() and exchange.get('result'):
            st.markdown("### ‚ö†Ô∏è R√©sultat partiel")
            st.write(exchange['result'])
        elif 'formatted' in locals() and formatted:
            st.markdown("### ‚ö†Ô∏è R√©sultat partiel")
            st.write(formatted)

# History
st.markdown("---")
st.markdown("### üìö Historique de la session")

exchanges = session.exchanges
if exchanges:
    render_chat_history(exchanges, show_code=session.show_code, limit=5)
else:
    st.info("üí≠ Posez votre premi√®re question pour commencer l'analyse.")

# Memory panel (expandable)
st.markdown("---")
render_memory_panel(expanded=False, show_actions=True)
